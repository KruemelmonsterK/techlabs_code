{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnings\n",
    "\n",
    "- Welche Grafik für was?\n",
    "    - siehe die zwei Bilder im Ordner\"Hintergrundbilder\"\n",
    "    -  https://uen.pressbooks.pub/uvumqr/chapter/4-3-data-organization-and-representations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???\n",
    "- ??? Was ist der Unterschied zwischen import x as x unf from datetime import datetime\n",
    "- ??? notebook 3: df = pd.read_csv(\"data/survey_results_public.csv\", index_col = \"Respondent\") -> warum benötige ich index_col?\n",
    "- ??? notebook 4: What is the difference between s = pd.Series([1, 2, 3, 4, 5]) and s = pd.DataFrame([1, 2, 3, 4, 5])\n",
    "- ??? Wie kann ich dataframe einfach löschen, damit ich nicht jedes Mal das Notebook neustarten muss, wenn ich den df zerschossen habe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- TODO: requirements.txt erstellen und exportieren -> Ziel: Jemand soll den Code von GitHub runter laden sollen und das Projekt lokal zum laufen bringen können\n",
    "- ~~TODO: Jeder Zelle kurz beschreiben (als Kommentat in ich-Perspektive)~~\n",
    "- ~~TODO: Alles Header klein schreiben und mit \"_\" verbinden~~\n",
    "- TODO: Am Anfang den dataframe verkleiner (z.B. nur auf Zeitraum von einem Jahr)\n",
    "- ~~TODO: In Dataanalysis der dataframe möglichst unberührt lassen -> für jeden Schritt in der Datenanalyse einen eigenen temporären dataframe erstellen (wenn benötigt: in diesem dataframe auch die eigenen features engineeren)~~\n",
    "- TODO: Um dataframe in einzelne Aktien zu zerlegen -> df.pivot() verwenden -> df.melt() macht dies wieder rückgängig\n",
    "- TODO: dataframe \"permanent\" im Notebook hochladen, damit ich dan nicht jedes Mal erneut hochladen muss\n",
    "- TODO: Später beschreiben wie der Pfad anzupassen ist, wenn die csv von wo anders hochgeladen werden soll\n",
    "- TODO: Columns in features umbenennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideen für die Zukunft\n",
    "- Modell für prediction von Aktienkursen erstellen\n",
    "- poetry verwenden (für Verwaltung von dependencies)\n",
    "- Präsentation mit Streamlit\n",
    "- Pipeline erstellen\n",
    "    - Daten werden automatisch (täglich/stündlich) gecrawlt\n",
    "    - alte Daten werden verworfen, neue Daten werden ergänzt\n",
    "    - Modell wird auf aktuellen Daten traineirt\n",
    "    - deployment als webservice oder ähnliches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I install the needed packages (only execute once)\n",
    "\n",
    "# install  packages\n",
    "# !conda install jupyter\n",
    "# !conda install numpy\n",
    "# !conda isntall pandas\n",
    "\n",
    "# TODO: Später hier alle packete installieren und importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I import the needed packages (only execute once)\n",
    "\n",
    "# import packages\n",
    "# !conda install jupyter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime # ??? Warum wird hier so und drunter und drüber anders importiert?\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Später hier alle packete installieren und importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way I limit the number of rows and columns (e.g. when calling \"df.head()\") (only execute once)\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "pd.set_option(\"display.max_rows\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way I can define the appearence of graphics created with seaborn (only execute once)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Description (statistical and visual go get a first impression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of given features:\n",
    "- date (Date): The date of the stock price data.\n",
    "- open (Open): The opening price of the stock on that date.\n",
    "- high (High): The highest price the stock reached during the trading day.\n",
    "- low (Low): The lowest price the stock reached during the trading day.\n",
    "- close (Close): The closing price of the stock on that date.\n",
    "- volume (Volume): The trading volume, i.e., the number of shares traded on that date.\n",
    "- dividends (Dividends): Dividends paid on that date (if any).\n",
    "- stock_splits (Stock Splits): Information about stock splits (if any).\n",
    "- brand_name (Brand_Name): The name of the brand or company.\n",
    "- ticker (Ticker): Ticker symbol for the stock.\n",
    "- industry_tag (Industry_Tag): The industry category or sector to which the brand belongs.\n",
    "- country (Country): The country where the brand is headquartered or primarily operates\n",
    "\n",
    "Description of engineered features:\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I read the csv and save it as dataframe (\"df\") (only excute once)\n",
    "\n",
    "df = pd.read_csv(\"data/World-Stock-Prices-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in df.columns:\n",
    "    print(f\"{name:<20} {df[name].nunique():>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I create a boxplot for each numeric feature \n",
    "numeric_features =  [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Dividends\", \"Stock Splits\", \"Capital Gains\"]\n",
    "\n",
    "for name in numeric_features:\n",
    "    sns.boxplot(data=df, y=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I create a boxplot for each ceatogoric feature (this cell fails after renaming the features in the next cells)\n",
    "categoric_features = [\"Brand_Name\",\t\"Ticker\",\t\"Industry_Tag\",\t\"Country\"]\n",
    "\n",
    "for name in categoric_features:\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    sns.histplot(data=df, x=name)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are my cells uniform? \n",
    "\n",
    "I unifiy the names of all features (no capital letters, all words are connected by \"_\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the features\n",
    "df.columns = df.columns.str.lower().str.replace(r'\\s+|[-\\s]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there duplicates? \n",
    "\n",
    "I remove rows which are duplicated and keep only one of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the format of the feature \"date\"?\n",
    "df.loc[0:6,\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before I change the type of date from string to datetime, I check for the granularity of the dataset\n",
    "\n",
    "df['date_for_check'] = df['date'].str[:10]\n",
    "df['time_for_check'] = df['date'].str[11:]\n",
    "\n",
    "grouped = df.groupby([\"date_for_check\", \"brand_name\"]).agg({\"time_for_check\": \"count\"})\n",
    "\n",
    "# grouped_with_filter = grouped[grouped[\"time_for_check\"] > 1]\n",
    "# grouped_with_filter\n",
    "\n",
    "filter = df.duplicated(subset=[\"date_for_check\", \"brand_name\"], keep='first') # TODO: Haben wir in den Übungen irgendwie anders gelöst mit den Filtern damals\n",
    "\n",
    "# I remove instances the appear multiple times\n",
    "df.drop(index=df[filter].index, inplace=True)\n",
    "\n",
    "# I remove column(s) that I don't need anymore\n",
    "df = df.drop(columns=['date_for_check', 'time_for_check'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there gaps in the time series? (TODO: Ist timeframe das richge \"wording\"?)\n",
    "\n",
    "I don't fill the gaps and I dont delete the gaps as I want to maintain the original characteristics of the dataset and avoid introducing potential biases.\n",
    "\n",
    "If gaps exist, I assume that it is due to the fact that stock exchanges are closed on weekends and and holidays. Other reasons could be possible as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime and extract only the date part\n",
    "df['date_for_check'] = pd.to_datetime(df['date'].str[:10])\n",
    "\n",
    "# Count occurrences of each date directly\n",
    "date_counts = df['date_for_check'].value_counts().sort_index().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "date_counts.columns = ['date', 'count']\n",
    "\n",
    "# Create a complete date range and ensure all dates are accounted for in the final DataFrame\n",
    "date_counts = date_counts.set_index('date').reindex(pd.date_range(date_counts['date'].min(), date_counts['date'].max()), fill_value=0).rename_axis('date').reset_index()\n",
    "\n",
    "# I remove column(s) that I don't need anymore\n",
    "df = df.drop(columns=['date_for_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counts = date_counts.loc[(date_counts['date'] >= \"2020-01-01\") & (date_counts['date'] <= \"2020-03-01\")]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "sns.histplot(data = date_counts, x=\"date\" ,binwidth=1, weights=\"count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data from string ti datetime\n",
    "df['date'] = pd.to_datetime(df['date'].str[:10])\n",
    "\n",
    "\n",
    "# add column for year, month and day\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day\"]= df[\"date\"].dt.day\n",
    "\n",
    "# Set data as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# reorder the features in a sensefull manner (first the dates, numrical data, finally categorical data)\n",
    "df = df[[\"year\", \"month\", \"day\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"dividends\", \"stock_splits\", \"capital_gains\", \"brand_name\",\t\"ticker\",\t\"industry_tag\",\t\"country\"]]\n",
    "\n",
    "# delet features that I dont need\n",
    "# df = df.drop(columns=['xyz', 'xyz']) #TODO: am Ende noch machen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there NAs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Kilian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual stock assessment (of a randomly chosen stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df[\"brand_name\"] == \"microsoft\")\n",
    "\n",
    "# APPLY FILTER HERE.\n",
    "df_windows = df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_windows, x='date', y='open')\n",
    "\n",
    "# Achsen und Titel anpassen (TODO: anpassen)\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Volumen')\n",
    "plt.title('Aktienvolumen über Zeit')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windows.reset_index(inplace=True)\n",
    "df_melted = df_windows.melt(id_vars=['date'], value_vars=['close', 'open'], var_name='feature', value_name='value')\n",
    "df_windows.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_melted, x='date', y='value', hue='feature')\n",
    "\n",
    "# Achsen und Titel anpassen\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Wert')\n",
    "plt.title('Entwicklung der Aktienpreise (open, close) über die Zeit')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windows.reset_index(inplace=True)\n",
    "df_melted = df_windows.melt(id_vars=['date'], value_vars=['high', 'low'], var_name='feature', value_name='value')\n",
    "df_windows.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_melted, x='date', y='value', hue='feature')\n",
    "\n",
    "# Achsen und Titel anpassen\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Wert')\n",
    "plt.title('Entwicklung der Aktienpreise (low, high) über die Zeit')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative stock assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 1: What is the accumulatie closing price by industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average closing price by industry\n",
    "industry_avg = df.groupby('industry_tag')['close'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=industry_avg.values, y=industry_avg.index)\n",
    "plt.title('Average Closing Price by Industry')\n",
    "plt.xlabel('Average Closing Price')\n",
    "plt.ylabel('Industry')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 2: What is the accumulatie closing price by industry over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "df.reset_index(inplace=True)\n",
    "average_open_by_sector = df[['date', 'ticker', 'open', 'industry_tag']].groupby(['date', 'industry_tag'])[['open']].mean().reset_index()\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=average_open_by_sector, x='date', y='open', hue='industry_tag')\n",
    "\n",
    "# modify the plot\n",
    "plt.title('Average Open time series ($) per sector')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.legend(title='Industry Sector', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 3: WHat is the average closing price by country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average closing price by country\n",
    "country_avg = df.groupby('country')['close'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=country_avg.values, y=country_avg.index)\n",
    "plt.title('Average Closing Price by Country')\n",
    "plt.xlabel('Average Closing Price')\n",
    "plt.ylabel('Country')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Ascan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Anahita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Minh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Sayed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Shirose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Analysis (Lars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. (Modeling and/or Prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techlabs_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
